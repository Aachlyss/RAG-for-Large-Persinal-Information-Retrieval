{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation using LangChain\n",
    "\n",
    "### 1. Setup and Initialization\n",
    "\n",
    "This block sets up the environment and initializes the required API clients:\n",
    "- Loads environment variables from a .env file.\n",
    "- Asserts that an OpenAI API key is available.\n",
    "- Initializes both the raw OpenAI client and a LangChain ChatOpenAI LLM for use in the RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"Missing an OpenAI key!!!!\"\n",
    "assert os.getenv(\"LANGCHAIN_API_KEY\"), \"Missing LangChain key!!!!\"\n",
    "assert os.getenv(\"LANGCHAIN_ENDPOINT\"), \"Missing endpoint!!!!\"\n",
    "\n",
    "openai_client = OpenAI()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Document \n",
    "- Here I am loading a book my mother gave me for testing purposes.\n",
    "- Veryfing the files existance.\n",
    "- Splitting text into overlapping chunks so no important information is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = \"data/book_abt_chairs.pdf\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    print(\"The PDF file does not exist!!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    ")\n",
    "splitted_docs = splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Embedding\n",
    "- Chose Embedding Model\n",
    "- Store vector in RAM\n",
    "- Retriever for most semantically similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = InMemoryVectorStore.from_documents(splitted_docs, embedding=embeddings)\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. \"clean_text\" and formatting\n",
    "- I added a method for removing the \"\\n\" because I noticed some inconsistency\n",
    "- format_doc method for joining docs and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    return text.replace(\"\\n\", \" \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_doc(docs):\n",
    "    cleaned_docs = []\n",
    "    for doc in docs:\n",
    "        cleaned = clean_text(doc.page_content)\n",
    "        print(\"Cleaned snippet:\", cleaned[:100])\n",
    "        cleaned_docs.append(cleaned)\n",
    "    return \"\\n\\n\".join(cleaned_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Expand Query method \n",
    "- I added last and adjusted the code accordingly, because the user's question might not match how the information appears in the document and it helps in cases where the user is not 100% sure what they are looking for.\n",
    "- First use of chaining in the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_query(question: str, llm_model) -> list[str]:\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Преформулирай следния въпрос в 5 разнообразни и семантично различни заявки:\\n\\n{question}\"\n",
    "    )\n",
    "    query_chain = RunnablePassthrough() | prompt | llm_model | StrOutputParser()\n",
    "    result = query_chain.invoke(question)\n",
    "    return [q.strip() for q in result.split(\"\\n\") if q.strip()] #Creates a list of 5 queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Similarity Search & Deduplication\n",
    "- Does similarity search for each generated query and removes duplicate texts if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def retrieve_documents(question: str, k: int = 2) -> list[Document]:\n",
    "    expanded_questions = expand_query(question, llm)\n",
    "    all_docs = []\n",
    "    for q in expanded_questions:\n",
    "        docs = vector_store.similarity_search(q, k=k)\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "    seen = set()\n",
    "    unique_docs = []\n",
    "    for doc in all_docs:\n",
    "        if doc.page_content not in seen:    # Remove duplicates\n",
    "            unique_docs.append(doc)\n",
    "            seen.add(doc.page_content)\n",
    "\n",
    "    return unique_docs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template in Bulgarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Отговори на въпроса САМО на базата на тази информация:\\n\\n{context}\\n\\n\"\n",
    "               \"Ако отговорът не е намерен, кажи 'не мога да отговоря на базата на информацията от документа.'\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to pull this out into a function for good practice even though it might be a bit useless here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str) -> str:\n",
    "    return rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": RunnableLambda(retrieve_documents) | RunnableLambda(format_doc), \"question\": RunnablePassthrough()}    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned snippet: 7  актуалност придобиват начините за подобряване на  физическото и психическо благосъстояние на потр\n",
      "Cleaned snippet: 103  3. Екологичен аспект  Обединяващата идея при проектирането на мебели е тяхната  екологичност - \n",
      "Отговор: Да, в документа се обръща особено внимание на добрата ергономия, която означава създаването на среда, позволяваща на тялото да се придвижва по различни начини.\n"
     ]
    }
   ],
   "source": [
    "question = \"Има ли тема за ергономия?\"\n",
    "response = answer_question(question)\n",
    "print(\"Отговор:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
